---
title: 'Project: Netflix Forecasting - Gradient Boosting (Laplace)'
author: "Max Horn, Elio Shyti, Lennart Bredthauer"
date: "2025-05-25"
output:
  html_document: default
  pdf_document: default
  mathjax: default
---

```{r Load Required Libraries, include=FALSE}
library(quantmod)
library(dplyr)
library(gbm)
library(Metrics)
library(ggplot2)
library(TTR)
library(gridExtra)
library(lubridate)
```
## 1. Data Collection and Feature Engineering
```{r Data Collection, message=FALSE, warning=FALSE}
start_date <- as.Date("2025-06-09") - years(5)

end_date   <- as.Date("2025-06-09")                 # Fixed cutoff at June 9, 2025

# Pull data
tickers <- c("NFLX", "DIS", "AMZN", "WBD")
getSymbols(tickers, src = "yahoo", from = start_date, to = end_date)

prices <- merge(Ad(NFLX), Ad(DIS), Ad(AMZN), Ad(WBD))
colnames(prices) <- c("NFLX", "DIS", "AMZN", "WBD")
prices <- na.omit(prices)
```
## 2. Feature Engineering
```{r feature engineering, message = F, warning=F}
df <- data.frame(Date = index(prices), coredata(prices))
for (l in 1:3) {
  df <- df %>% mutate(
    !!paste0("NFLX_lag_", l) := lag(NFLX, l),
    !!paste0("DIS_lag_", l) := lag(DIS, l),
    !!paste0("AMZN_lag_", l) := lag(AMZN, l),
    !!paste0("WBD_lag_", l) := lag(WBD, l)
  )
}
df <- df %>% mutate(
  SMA_5 = SMA(NFLX, 5),
  RSI_14 = RSI(NFLX, 14),
  Volatility = runSD(NFLX, 5),
  Log_Return = log(lead(NFLX, 1)) - log(NFLX)
) %>% na.omit()
```
## 3. Forecast with Laplace Loss using gbm
```{r gbm_laplace, message = F, warning=F}
train_window <- 252
forecast_horizons <- 1:5
forecast_results <- list()

for (h in forecast_horizons) {
  rolling_preds <- data.frame()
  for (i in seq(train_window, nrow(df) - h)) {
    train_data <- df[(i - train_window + 1):i, ]
    model <- gbm(Log_Return ~ . - Date - Log_Return,
                 data = train_data,
                 distribution = "laplace",
                 n.trees = 2500,
                 interaction.depth = 3,
                 shrinkage = 0.05,
                 verbose = FALSE)
    pred_return <- predict(model, df[i + 1, ], n.trees = 2500)
    price_today <- df$NFLX[i + 1]
    pred_price <- price_today * exp(pred_return)

    mad_err <- mad(train_data$Log_Return - predict(model, train_data, n.trees = 2500), na.rm = TRUE)
    pred_best <- price_today * exp(pred_return + 6.64 * mad_err)
    pred_worst <- price_today * exp(pred_return - 6.64 * mad_err)

    rolling_preds <- rbind(rolling_preds, data.frame(
      Date = df$Date[i + h],
      Actual = df$NFLX[i + h],
      Predicted = pred_price,
      Best_Case = pred_best,
      Worst_Case = pred_worst
    ))
  }
  forecast_results[[paste0("Horizon_", h)]] <- rolling_preds
}
```
### optional plot
```{r plot_laplace_forecast, message=FALSE, warning=FALSE}
plot_list <- lapply(1:5, function(h) {
  data <- tail(forecast_results[[paste0("Horizon_", h)]], 60)
  ggplot(data, aes(x = Date)) +
    geom_line(aes(y = Actual), color = "black") +
    geom_line(aes(y = Predicted), color = "blue", linetype = "dashed") +
    #geom_line(aes(y = Best_Case), color = "forestgreen", linetype = "dotted") +
    #geom_line(aes(y = Worst_Case), color = "red", linetype = "dotted") +
    labs(title = paste("Forecast Horizon:", h, "Day(s)"),
         subtitle = "Zoomed Rolling Window GBR Forecast (Laplace)",
         y = "Price (USD)", x = "Date") +
    theme_minimal()
})
grid.arrange(grobs = plot_list, ncol = 1)
```
## 4. Zoomed-In Forecast (Laplace, Last 30 Observations)
```{r zoom_laplace, message=FALSE, warning=FALSE}
data_zoom <- tail(forecast_results[["Horizon_5"]], 30)
zoom_plot <- ggplot(data_zoom, aes(x = Date)) +
  geom_line(aes(y = Actual), color = "black") +
  geom_line(aes(y = Predicted), color = "blue", linetype = "dashed") +
  #geom_line(aes(y = Best_Case), color = "forestgreen", linetype = "dotted") +
  #geom_line(aes(y = Worst_Case), color = "red", linetype = "dotted") +
  labs(title = "Zoomed-In Forecast (Laplace): 5-Day Ahead",
       subtitle = "Last 30 Predictions",
       y = "Price (USD)", x = "Date") +
  theme_minimal()
print(zoom_plot)
```
# 5. Printing Metrics for Performance Evaluation
```{r metrics_laplace, message=FALSE, warning=FALSE}
laplace_metrics <- data.frame(Horizon = integer(), MAE = numeric(), RMSE = numeric(), MAPE = numeric())
for (h in 1:5) {
  preds <- forecast_results[[paste0("Horizon_", h)]]
  mae_val <- mean(abs(preds$Actual - preds$Predicted))
  rmse_val <- sqrt(mean((preds$Actual - preds$Predicted)^2))
  mape_val <- mean(abs((preds$Actual - preds$Predicted) / preds$Actual)) * 100
  laplace_metrics <- rbind(laplace_metrics, data.frame(Horizon = h, MAE = mae_val, RMSE = rmse_val, MAPE = mape_val))
}
print(laplace_metrics)
```

Explanation: In Laplace regression, the **absolute deviations** are minimized rather than squared deviations (as in Gaussian/normal). Therefore, the appropriate error spread for uncertainty estimation is the **Median Absolute Deviation (MAD)** rather than standard deviation (SD), as MAD is more robust to outliers. That's why we replaced `sd()` with `mad()` when constructing worst/best case scenario bands.

## 6. Outlier Analysis

```{r}
library(ggplot2)

# Choose Laplace forecast horizon
data_laplace <- forecast_results[["Horizon_1"]]

# Calculate absolute forecast error
data_laplace$Error <- abs(data_laplace$Actual - data_laplace$Predicted)

# Extract top 5 largest prediction errors
top_outliers_laplace <- data_laplace[order(-data_laplace$Error), ][1:5, ]

# Plot with outliers highlighted
ggplot(data_laplace, aes(x = Date)) +
  geom_line(aes(y = Actual), color = "black", size = 1) +
  geom_line(aes(y = Predicted), color = "blue", linetype = "dashed", size = 1) +
  geom_point(data = top_outliers_laplace, aes(y = Predicted), color = "red", size = 3) +
  geom_text(data = top_outliers_laplace, aes(y = Predicted, label = round(Error, 2)), 
            vjust = -1, color = "red", size = 3) +
  labs(title = "Laplace Forecast vs Actual (Top Outliers Highlighted)",
       subtitle = "Red dots show largest prediction errors using Laplace loss",
       y = "Price (USD)", x = "Date") +
  theme_minimal()
```
In Comparison, the Gaussian model highlights outliers that are more severe in squared error terms (i.e. extreme values), while Laplace model is more robust and focuses on consistently large absolute deviations. This makes Laplace the better choise for noisy models (proven by the application of the median instead of mean). 

We can also observe that the Gaussian model has large outliers during sharp downward shocks and the Laplace for rapid increases. 

```{r}
# Plot error over time
ggplot(data_laplace, aes(x = Date, y = Error)) +
  geom_line(color = "darkred") +
  geom_point(data = top_outliers_laplace, color = "red", size = 2) +
  labs(title = "Prediction Error Over Time (Laplace)",
       subtitle = "Spikes indicate large deviations in Laplace forecast",
       y = "Absolute Error (USD)", x = "Date") +
  theme_minimal()
```


## 7.Variable Importance
Hence, the examination of the influence of features (especially external) is of interest. We want to determine the features which are the most "important" for our model.
```{r relative influence laplace, message = FALSE, warning = FALSE}
full_model_laplace <- gbm(Log_Return ~ . - Date - Log_Return,
                          data = df,
                          distribution = "laplace",
                          n.trees = 2500,
                          interaction.depth = 3,
                          shrinkage = 0.05,
                          verbose = FALSE)

summary(full_model_laplace, las = 1, cBar = 10)
```
## 8. Forecast for  5 days in future
```{r}
# Step 8 — SAFE 5-Day Ahead Forecast with Business Days

latest_data <- tail(df, 252)  # training window for final model
future_forecast_laplace <- data.frame()  # create empty df

# Train final Laplace model
final_model_laplace <- gbm(Log_Return ~ . - Date - Log_Return,
                           data = latest_data,
                           distribution = "laplace",
                           n.trees = 2500,
                           interaction.depth = 3,
                           shrinkage = 0.05,
                           verbose = FALSE)

# Compute MAD for scenario bands
train_preds <- predict(final_model_laplace, latest_data, n.trees = 2500)
train_resid <- latest_data$Log_Return - train_preds
mad_err <- mad(train_resid, na.rm = TRUE)

# Generate next 5 business days (skip weekends)
last_date <- max(df$Date)

# create sequence of next 10 calendar days
next_dates <- seq(from = last_date + 1, by = 1, length.out = 10)
# filter only weekdays (Mon–Fri)
next_dates <- next_dates[weekdays(next_dates) %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")][1:5]

# Start from latest known observation
last_row <- tail(df, 1)

# Forecast next 5 days
for (d in 1:5) {
  
  pred_return <- predict(final_model_laplace, last_row, n.trees = 2500)
  price_today <- last_row$NFLX
  pred_price <- price_today * exp(pred_return)
  
  best_case <- price_today * exp(pred_return + 6.64 * mad_err)
  worst_case <- price_today * exp(pred_return - 6.64 * mad_err)
  
  next_date <- next_dates[d]
  
  future_forecast_laplace <- rbind(future_forecast_laplace, data.frame(
    Day = d,
    Date = next_date,
    Predicted = pred_price,
    Best_Case = best_case,
    Worst_Case = worst_case
  ))
  
  # Update last_row
  new_row <- last_row
  new_row$NFLX <- pred_price
  
  # Update lags
  for (l in 3:2) {
    new_row[[paste0("NFLX_lag_", l)]] <- new_row[[paste0("NFLX_lag_", l - 1)]]
    new_row[[paste0("DIS_lag_", l)]] <- new_row[[paste0("DIS_lag_", l - 1)]]
    new_row[[paste0("AMZN_lag_", l)]] <- new_row[[paste0("AMZN_lag_", l - 1)]]
    new_row[[paste0("WBD_lag_", l)]] <- new_row[[paste0("WBD_lag_", l - 1)]]
  }
  new_row$NFLX_lag_1 <- new_row$NFLX
  new_row$DIS_lag_1 <- tail(df$DIS, 1)
  new_row$AMZN_lag_1 <- tail(df$AMZN, 1)
  new_row$WBD_lag_1 <- tail(df$WBD, 1)
  
  # Technical Indicators
  temp_series <- c(tail(df$NFLX, 4), new_row$NFLX)
  new_row$SMA_5 <- mean(temp_series)
  
  simulated_prices <- c(tail(df$NFLX, 13), future_forecast_laplace$Predicted)
  temp_rsi_series <- c(simulated_prices, pred_price)
  
  if (sum(!is.na(temp_rsi_series)) >= 14) {
    rsi_val <- tryCatch({ RSI(temp_rsi_series, 14)[length(temp_rsi_series)] }, error = function(e) NA)
  } else {
    rsi_val <- NA
  }
  new_row$RSI_14 <- ifelse(is.na(rsi_val), last_row$RSI_14, rsi_val)
  new_row$Volatility <- sd(temp_series)
  
  last_row <- new_row
}

# Output forecast table
print(future_forecast_laplace)

```




```{r}
# Plot 5-day ahead Laplace scenario forecast
ggplot(future_forecast_laplace, aes(x = Date)) +
  geom_line(aes(y = Predicted), color = "blue", linetype = "dashed", size = 1.1) +
  geom_line(aes(y = Best_Case), color = "forestgreen", linetype = "dotted", size = 1) +
  geom_line(aes(y = Worst_Case), color = "red", linetype = "dotted", size = 1) +
  geom_point(aes(y = Predicted), color = "blue") +
  geom_point(aes(y = Best_Case), color = "forestgreen") +
  geom_point(aes(y = Worst_Case), color = "red") +
  labs(title = "5-Day Ahead Forecast with Scenario Bounds (Laplace)",
       subtitle = "Best (Green), Predicted (Blue), Worst (Red) using Laplace/MAD",
       x = "Date", y = "Forecasted Price (USD)") +
  theme_minimal()
```
We achieved wider boundaries, due to Laplace Distribution, compared to the Gaussian Loss Function Model.



